from transformers import AutoImageProcessor, AutoModelForImageClassification
import torch
from PIL import Image
import io

# üü¢ Load m√¥ h√¨nh m·ªôt l·∫ßn khi import module
processor = AutoImageProcessor.from_pretrained("dima806/facial_emotions_image_detection")
model = AutoModelForImageClassification.from_pretrained("dima806/facial_emotions_image_detection")

# Danh s√°ch c√°c c·∫£m x√∫c m√¥ h√¨nh c√≥ th·ªÉ nh·∫≠n di·ªán
EMOTION_LABELS = ["angry", "disgust", "fear", "happy", "neutral", "sad", "surprise"]

def predict_emotion(image_bytes):
    """Nh·∫≠n ·∫£nh d∆∞·ªõi d·∫°ng bytes v√† tr·∫£ v·ªÅ c·∫£m x√∫c d·ª± ƒëo√°n."""
    try:
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
        inputs = processor(image, return_tensors="pt")

        # D·ª± ƒëo√°n c·∫£m x√∫c
        with torch.no_grad():
            outputs = model(**inputs)

        # L·∫•y c·∫£m x√∫c d·ª± ƒëo√°n c√≥ x√°c su·∫•t cao nh·∫•t
        predicted_class = torch.argmax(outputs.logits, dim=-1).item()
        predicted_emotion = EMOTION_LABELS[predicted_class]

        return predicted_emotion
    except Exception as e:
        print(f"‚ùå Error prediction proccess: {e}")
        return None
